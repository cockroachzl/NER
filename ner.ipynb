{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tnrange\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, data_dir, args):    \n",
    "        \n",
    "        # loading vocab (we require this to map words to their indices)\n",
    "        vocab_path = os.path.join(data_dir, 'words.txt')\n",
    "        self.vocab = {}\n",
    "        with open(vocab_path, encoding='utf-8') as f:\n",
    "            for i, l in enumerate(f.read().splitlines()):\n",
    "                self.vocab[l] = i\n",
    "        \n",
    "        # setting the indices for UNKnown words and PADding symbols\n",
    "        self.unk_ind = self.vocab[args['unk_word']]\n",
    "        self.pad_ind = self.vocab[args['pad_word']]\n",
    "                \n",
    "        # loading tags (we require this to map tags to their indices)\n",
    "        tags_path = os.path.join(data_dir, 'tags.txt')\n",
    "        self.tag_map = {}\n",
    "        with open(tags_path, encoding='utf-8') as f:\n",
    "            for i, t in enumerate(f.read().splitlines()):\n",
    "                self.tag_map[t] = i\n",
    "\n",
    "    def load_sentences_labels(self, sentences_file, labels_file, d):\n",
    "        \"\"\"\n",
    "        Loads sentences and labels from their corresponding files. Maps tokens and tags to their indices and stores\n",
    "        them in the provided dict d.\n",
    "\n",
    "        Args:\n",
    "            sentences_file: (string) file with sentences with tokens space-separated\n",
    "            labels_file: (string) file with NER tags for the sentences in labels_file\n",
    "            d: (dict) a dictionary in which the loaded data is stored\n",
    "        \"\"\"\n",
    "\n",
    "        sentences = []\n",
    "        labels = []\n",
    "\n",
    "        with open(sentences_file, encoding='utf-8') as f:\n",
    "            for sentence in f.read().splitlines():\n",
    "                # replace each token by its index if it is in vocab\n",
    "                # else use index of UNK_WORD\n",
    "                s = [self.vocab[token] if token in self.vocab \n",
    "                     else self.unk_ind\n",
    "                     for token in sentence.split(' ')]\n",
    "                sentences.append(s)\n",
    "        \n",
    "        with open(labels_file, encoding='utf-8') as f:\n",
    "            for sentence in f.read().splitlines():\n",
    "                # replace each label by its index\n",
    "                l = [self.tag_map[label] for label in sentence.split(' ')]\n",
    "                labels.append(l)        \n",
    "\n",
    "        # checks to ensure there is a tag for each token\n",
    "        assert len(labels) == len(sentences)\n",
    "        for i in range(len(labels)):\n",
    "            assert len(labels[i]) == len(sentences[i])\n",
    "\n",
    "        # storing sentences and labels in dict d\n",
    "        d['data'] = sentences\n",
    "        d['labels'] = labels\n",
    "        d['size'] = len(sentences)\n",
    "\n",
    "    def load_data(self, types, data_dir):\n",
    "        \"\"\"\n",
    "        Loads the data for each type in types from data_dir.\n",
    "\n",
    "        Args:\n",
    "            types: (list) has one or more of 'train', 'val', 'test' depending on which data is required\n",
    "            data_dir: (string) directory containing the dataset\n",
    "\n",
    "        Returns:\n",
    "            data: (dict) contains the data with labels for each type in types\n",
    "\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            if split in types:\n",
    "                sentences_file = os.path.join(data_dir, split, \"sentences.txt\")\n",
    "                labels_file = os.path.join(data_dir, split, \"labels.txt\")\n",
    "                data[split] = {}\n",
    "                self.load_sentences_labels(sentences_file, labels_file, data[split])\n",
    "\n",
    "        return data\n",
    "\n",
    "    def data_iterator(self, data, args, shuffle=False):\n",
    "        \"\"\"\n",
    "        Returns a generator that yields batches data with labels. Batch size is args['batch_size']. Expires after one\n",
    "        pass over the data.\n",
    "\n",
    "        Args:\n",
    "            data: (dict) contains data which has keys 'data', 'labels' and 'size'\n",
    "            args: (dict) hyperparameters of the training process.\n",
    "            shuffle: (bool) whether the data should be shuffled\n",
    "\n",
    "        Yields:\n",
    "            batch_data: dimension batch_size x seq_len with the sentence data\n",
    "            batch_labels: dimension batch_size x seq_len with the corresponding labels\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # make a list that decides the order in which we go over the data- this avoids explicit shuffling of data\n",
    "        order = list(range(data['size']))\n",
    "        if shuffle:\n",
    "            random.seed(230)\n",
    "            random.shuffle(order)\n",
    "            \n",
    "        batch_size = args['batch_size']\n",
    "\n",
    "        # one pass over data\n",
    "        for i in range((data['size']+1)//args['batch_size']):\n",
    "            # fetch sentences and tags\n",
    "            batch_sentences = [data['data'][idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "            batch_tags = [data['labels'][idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "\n",
    "            # compute length of longest sentence in batch\n",
    "            batch_max_len = max([len(s) for s in batch_sentences])\n",
    "\n",
    "            # prepare a numpy array with the data, initialising the data with pad_ind and all labels with -1\n",
    "            # initialising labels to -1 differentiates tokens with tags from PADding tokens\n",
    "            batch_data = self.pad_ind*np.ones((len(batch_sentences), batch_max_len))\n",
    "            batch_labels = -1*np.ones((len(batch_sentences), batch_max_len))\n",
    "\n",
    "            # copy the data to the numpy array\n",
    "            for j in range(len(batch_sentences)):\n",
    "                cur_len = len(batch_sentences[j])\n",
    "                batch_data[j][:cur_len] = batch_sentences[j]\n",
    "                batch_labels[j][:cur_len] = batch_tags[j]\n",
    "\n",
    "            # since all data are indices, we convert them to torch LongTensors\n",
    "            batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels)\n",
    "\n",
    "            # shift tensors to GPU if available\n",
    "            if args['cuda']:\n",
    "                batch_data, batch_labels = batch_data.cuda(), batch_labels.cuda()\n",
    "    \n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, out_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # the embedding takes as input the vocab_size and the embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # the LSTM takes as input the size of its input (embedding_dim), its hidden size\n",
    "        # for more details on how to use it, check out the documentation\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # the fully connected layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq: contains a batch of sentences, of dimension batch_size x seq_len, where seq_len is\n",
    "               the length of the longest sentence in the batch. For sentences shorter than seq_len, the remaining\n",
    "               tokens are PADding tokens. Each row is a sentence with each element corresponding to the index of\n",
    "               the token in the vocab.\n",
    "\n",
    "        Returns:\n",
    "            out: dimension batch_size*seq_len x num_tags with the log probabilities of tokens for each token\n",
    "                 of each sentence.\n",
    "        \"\"\"\n",
    "        #                                -> batch_size x seq_len\n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        seq = self.embedding(seq)            # dim: batch_size x seq_len x embedding_dim\n",
    "\n",
    "        # run the LSTM along the sentences of length seq_len\n",
    "        seq, _ = self.lstm(seq)              # dim: batch_size x seq_len x lstm_hidden_dim\n",
    "\n",
    "        # make the Variable contiguous in memory (a PyTorch artefact)\n",
    "        seq = seq.contiguous()\n",
    "\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        seq = seq.view(-1, seq.shape[2])       # dim: batch_size*seq_len x lstm_hidden_dim\n",
    "\n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        seq = self.fc(seq)                   # dim: batch_size*seq_len x num_tags\n",
    "\n",
    "        # apply log softmax on each token's output (this is recommended over applying softmax\n",
    "        # since it is numerically more stable)\n",
    "        return F.log_softmax(seq, dim=1)   # dim: batch_size*seq_len x num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the cross entropy loss given outputs from the model and labels for all tokens. Exclude loss terms\n",
    "    for PADding tokens.\n",
    "\n",
    "    Args:\n",
    "        outputs: (Variable) dimension batch_size*seq_len x num_tags - log softmax output of the model\n",
    "        labels: (Variable) dimension batch_size x seq_len where each element is either a label in [0, 1, ... num_tag-1],\n",
    "                or -1 in case it is a PADding token.\n",
    "\n",
    "    Returns:\n",
    "        loss: (Variable) cross entropy loss for all tokens in the batch\n",
    "\n",
    "    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n",
    "          demonstrates how you can easily define a custom loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    # since PADding tokens have label -1, we can generate a mask to exclude the loss from those terms\n",
    "    mask = (labels >= 0).float()\n",
    "\n",
    "    # indexing with negative values is not supported. Since PADded tokens have label -1, we convert them to a positive\n",
    "    # number. This does not affect training, since we ignore the PADded tokens with the mask.\n",
    "    labels = labels % outputs.shape[1]\n",
    "\n",
    "    num_tokens = int(torch.sum(mask).item())\n",
    "\n",
    "    # compute cross entropy loss for all tokens (except PADding tokens), by multiplying with mask.\n",
    "    return -torch.sum(outputs[range(outputs.shape[0]), labels]*mask)/num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the accuracy, given the outputs and labels for all tokens. Exclude PADding terms.\n",
    "\n",
    "    Args:\n",
    "        outputs: (np.ndarray) dimension batch_size*seq_len x num_tags - log softmax output of the model\n",
    "        labels: (np.ndarray) dimension batch_size x seq_len where each element is either a label in\n",
    "                [0, 1, ... num_tag-1], or -1 in case it is a PADding token.\n",
    "\n",
    "    Returns: (float) accuracy in [0,1]\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.ravel()\n",
    "\n",
    "    # since PADding tokens have label -1, we can generate a mask to exclude the loss from those terms\n",
    "    mask = (labels >= 0)\n",
    "\n",
    "    # np.argmax gives us the class predicted for each token by the model\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "    # compare outputs with labels and divide by number of tokens (excluding PADding tokens)\n",
    "    return np.sum(outputs==labels)/float(np.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    # could add more metrics such as accuracy for each token type\n",
    "}\n",
    "class RunningAverage():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.total / float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, data_iterator, metrics, args, num_steps):\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    t = tnrange(num_steps) \n",
    "    for i in t:\n",
    "        # fetch the next training batch\n",
    "        train_batch, labels_batch = next(data_iterator)\n",
    "\n",
    "        # compute model output and loss\n",
    "        output_batch = model(train_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if i % args['save_summary_steps'] == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
    "                             for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item()\n",
    "            summ.append(summary_batch)\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, data_iterator, metrics, args, num_steps):\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    # compute metrics over the dataset\n",
    "    for _ in range(num_steps):\n",
    "        # fetch the next evaluation batch\n",
    "        data_batch, labels_batch = next(data_iterator)\n",
    "        \n",
    "        # compute model output\n",
    "        output_batch = model(data_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.item()\n",
    "        summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    logging.info(\"- Eval metrics : \" + metrics_string)\n",
    "    return metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_data, val_data, optimizer, loss_fn, metrics, args):\n",
    "    \"\"\"\n",
    "        train_data: (dict) training data with keys 'data' and 'labels'\n",
    "        val_data: (dict) validaion data with keys 'data' and 'labels'\n",
    "    \"\"\"\n",
    "        \n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in tnrange(args['num_epochs']):\n",
    "        # Run one epoch\n",
    "        logging.info(\"Epoch {}/{}\".format(epoch + 1, args['num_epochs']))\n",
    "\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        num_steps = (args['train_size'] + 1) // args['batch_size']\n",
    "        train_data_iterator = data_loader.data_iterator(train_data, args, shuffle=True)\n",
    "        train(model, optimizer, loss_fn, train_data_iterator, metrics, args, num_steps)\n",
    "            \n",
    "        # Evaluate for one epoch on validation set\n",
    "        num_steps = (args['val_size'] + 1) // args['batch_size']\n",
    "        val_data_iterator = data_loader.data_iterator(val_data, args, shuffle=False)\n",
    "        val_metrics = evaluate(model, loss_fn, val_data_iterator, metrics, args, num_steps)\n",
    "        \n",
    "        val_acc = val_metrics['accuracy']\n",
    "        is_best = val_acc >= best_val_acc\n",
    "            \n",
    "        # If best_eval, best_save_path        \n",
    "        if is_best:\n",
    "            logging.info(\"- Found new best accuracy\")\n",
    "            best_val_acc = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters from json file\n",
    "args = {\n",
    "    'data_dir': 'data/kaggle',\n",
    "    'model_dir': 'experiments/base_model',\n",
    "    \n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 5,\n",
    "    \"num_epochs\": 3, # change this to 10 or more\n",
    "\n",
    "    \"hidden_dim\": 50,\n",
    "    \"embedding_dim\": 50,\n",
    "\n",
    "    \"save_summary_steps\": 100,\n",
    "    \n",
    "    \"train_size\": 33570,\n",
    "    \"dev_size\": 7194,\n",
    "    \"test_size\": 7194,\n",
    "    \"vocab_size\": 35180,\n",
    "    \"number_of_tags\": 17,\n",
    "    \"pad_word\": \"<pad>\",\n",
    "    \"pad_tag\": \"O\",\n",
    "    \"unk_word\": \"UNK\"\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# use GPU if available\n",
    "args['cuda'] = torch.cuda.is_available()\n",
    "    \n",
    "# Set the random seed for reproducible experiments\n",
    "torch.manual_seed(6677)\n",
    "if args['cuda']: torch.cuda.manual_seed(6677)\n",
    "\n",
    "# load data\n",
    "data_loader = DataLoader(args['data_dir'], args)\n",
    "data = data_loader.load_data(['train', 'val'], args['data_dir'])\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "\n",
    "# specify the train and val dataset sizes\n",
    "args['train_size'] = train_data['size']\n",
    "args['val_size'] = val_data['size']\n",
    "\n",
    "# Define the model and optimizer\n",
    "model = NER(args['vocab_size'], args['embedding_dim'], args['hidden_dim'], args['number_of_tags']).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args['learning_rate'])\n",
    "    \n",
    "# fetch loss function and metrics\n",
    "loss_fn = loss_fn\n",
    "metrics = metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER(\n",
       "  (embedding): Embedding(35180, 50)\n",
       "  (lstm): LSTM(50, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9add4c8a5e943cbaaeeb7c9ccbcb2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f1dae3280140c6ade650648aff6131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6714), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c434eb59d4774506a8138fac88fb8c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6714), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0ba363885f44d2a495413c7c8f5bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6714), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(model, train_data, val_data, optimizer, loss_fn, metrics, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (User)",
   "language": "python",
   "name": "user_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
